\documentclass{article}

\usepackage[margin=1in]{geometry}
\usepackage{graphicx, amsmath, amsthm, amssymb, enumitem, lipsum, algorithm, algpseudocode}

\setlist[enumerate]{leftmargin=1.25cm, nosep}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}

\newenvironment{note}[2][Note]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\newenvironment{fact}[2][Fact]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\newenvironment{definition}[2][Definition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\newenvironment{proposition}[2][Proposition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\hspace{-1ex}\bfseries #2.}]}{\end{trivlist}}

\newenvironment{principle}[2][Principle]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\newenvironment{envsection}[1]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}


\title{CS 4980: Capstone Research\\
        Notes}
\author{Professor Mark Floryan,\\
        compiled by Grady Hollar}
\date{Fall 2025}

\begin{document}
\setlength{\abovedisplayskip}{4pt}
\setlength{\belowdisplayskip}{4pt}
\maketitle



\begin{center}
    \textsc{X. Basic Definitions}
\end{center}

\section{Basic Definitions}

What is an approximation algorithm?

\subsection{Min-max relations}


\begin{center}
    \textsc{X. Some basic examples}
\end{center}

Vertex cover, set cover.




% \begin{center}
%     \textsc{X. Randomization and LP Methods}
% \end{center}

\section{Randomization and LP Methods}

\subsection{A simple MAX-3SAT algorithm}

(we assume each clause contains exactly 3 distinct variables + no clause contains both a variable and its negation (you can relax this second one tho?))

\begin{definition}{(Randomized Approximation Algorithm)}{}
    We say that a randomized algorithm for a problem has an \textit{approximation ratio} of $\rho(n)$ if, for any input of size $n$, the expected cost of the solution produced by the randomized algorithm is within a factor of $\rho(n)$ of the cost of an optimal solution.
\end{definition}

% \begin{definition}{(Randomized Approximation Algorithm)}{}
%     An algorithm $\mathcal{A}$ is said to be a \textit{$\rho$-factor approximation algorithm} for an optimization problem $\Pi$ if, for every instance $I$, $\mathcal{A}$ produces a feasible solution $s$ for $I$ such that
%     \[
%     f_\Pi(I,s) \leq \rho(|I|) \cdot \text{OPT}_\Pi(I) \qquad \Bigl( f_\Pi(I,s) \geq \rho(|I|) \cdot \text{OPT}_\Pi(I) \Bigr),
%     \]
%     and $\mathcal{A}$'s running time is bounded by some polynomial in $|I|$.
% \end{definition}

\begin{envsection}{Optimization Problem (MAX-$3$SAT)}
    Given a 3-CNF formula $\phi$, find an assignment of $\phi$ that satisfies the largest number of clauses.
\end{envsection}


\begin{algorithm}
    % \renewcommand{\thealgorithm}{}
    \caption{\textsc{Approx-MAX-3SAT}$(\phi)$}
    \begin{algorithmic}
        \For{$x_i \in \phi$}
            \State Assign $x_i$ randomly to be 0 or 1
        \EndFor
        \State \Return the assignment
    \end{algorithmic}
\end{algorithm}

\begin{theorem}{2.1}{}
    Algorithm 1 is an $8/7$-approximation for MAX-3SAT.

    \begin{proof}
        Let $\phi$ be a 3-CNF formula with $n$ variables $x_1,x_2,\dots,x_n$ and $m$ clauses. For $1 \leq i \leq m$, define the random variable
        \[
        Y_i =
        \begin{cases}
            1, &\text{clause $i$ is satisfied}\\
            0, &\text{otherwise}
        \end{cases}.
        \]
        Then, the number of clauses satisfied overall is modeled by the random variable defined by
        \[
        Y = \sum_{i=1}^m Y_i.
        \]
        So, it suffices to compute $E[Y]$. Since each variable is set to 1 with probability $1/2$ and 0 with probability $1/2$, and a clause is not satisfied only if all three of its literals are set to 0, we have
        \[
        P[Y_i = 0] = (1/2)^3 = 1/8,
        \]
        so that
        \[
        P[Y_i = 1] = 1 - 1/8 = 7/8.
        \]
        Computing $E[Y_i]$ then gives us
        \[
        E[Y_i] = 1 \cdot 7/8 + 0 \cdot 1/8 = 7/8.
        \]
        We may now compute
        \begin{align*}
            E[Y] &= E \left[ \sum_{i=1}^m Y_i \right]\\
            &= \sum_{i=1}^{m} E[Y_i]\\
            &= \sum_{i=1}^{m} 7/8\\
            &= 7m/8.
        \end{align*}
        Since the maximum amount of clauses that can be satisfied in $\phi$ is $m$, the approximation ratio is at most $m/(7m/8) = 8/7$.
    \end{proof}
\end{theorem}

\subsection{The weighted vertex cover problem}

\begin{envsection}{Optimization Problem (Minimum Weight Vertex Cover)}
    Given an undirected graph $G = (V,E)$ and a weight function $w: V \to \Q^+$, find a vertex cover $C \subseteq V$ of minimum weight $w(C) = \sum_{v \in C} w(v)$.
\end{envsection}

Consider the following linear program:\\
\\
minimize 
$$\displaystyle \sum_{v \in V}w(v) \cdot x_v$$
subject to
\begin{align*}
    x_u + x_v &\geq 1 \quad \forall (u,v) \in E\\
    x_v &\leq 1 \quad \forall v \in V\\
    x_v &\geq 0 \quad \forall v \in V
\end{align*}

\begin{algorithm}
    % \renewcommand{\thealgorithm}{}
    \caption{\textsc{Approx-Min-Weight-VC}$(G, w)$}
    \begin{algorithmic}
        \State $C = \emptyset$
        \State compute an optimal solution $\overline{x}$ to the above linear program.
        \For{$v \in V$}
            \If{$\overline{x}_v \geq 1/2$}
                \State $C = C \cup \{v\}$
            \EndIf
        \EndFor
        \State \Return $C$
    \end{algorithmic}
\end{algorithm}

\begin{theorem}{2.2}
    Algorithm 2 is a 2-approximation algorithm for the minimum weight vertex cover problem.

    \begin{proof}
        Want to show:\vspace{3pt}
        \begin{enumerate}
            \item[] Why is $C$ a cover?\vspace{3pt}
            \item[] Compare an optimal cover $C^*$ to the objective function value for optimal solution of the LP $z^*$. Obtain $z^* \leq w(C^*)$. ($C^*$ is a feasible solution to the LP)\vspace{3pt}
            \item[] Obtain $z^* \geq w(C)/2$. Key step:
                \[
                z^* \geq \sum_{v \in V: \overline{x}_v \geq 1/2} w(v) \cdot \overline{x}_v
                \]
            \item[] Combine inequalities to get $w(C) \leq 2w(C^*)$.
        \end{enumerate}
    \end{proof}
\end{theorem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%% XX %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%% END XX %%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}